load("doubleboot_GC2017_run.RData")
library(aster)
head(GC_Va.hat)
setwd("C:/Users/Mason Kulbaba/Dropbox/Rscripts/chamaecrista-adaptive-capacity/bootstrap/GC/2017")
# load packages
library(aster)
# load raster output
load("rout2017.RData")
# load redata file
load("redata2017.RData")
# load modmat.siredam matrix
load("modmat.siredam2017.RData")
modmat.siredamGC<- as.matrix(modmat.siredam2017)
set.seed(1729)
#########################################################################
### 2. PREPARE FOR BOOTSTRAPPING
#########################################################################
### set up graphical model
pred<- c(0,1,2,3,4) #make sure this matches your model
# designate family for each node in graphical model
fam<- c(1,1,2,2,2) #make sure this matches your model
# generate "hat" estimates from data
alpha.hat <- rout2017$alpha
sigma.hat <- rout2017$sigma
nu.hat <- rout2017$nu
b.hat <- rout2017$b
c.hat <- rout2017$c
sout <- summary(rout2017)
se.alpha.hat <- sout$alpha[ , "Std. Error"]
se.sigma.hat <- sout$sigma[ , "Std. Error"]
se.nu.hat <- sout$nu[ , "Std. Error"]
fixed <- rout2017$fixed
random <- rout2017$random
modmat.tot <- cbind(fixed, Reduce(cbind, random))
nfix <- ncol(fixed)
nrand <- sapply(random, ncol)
a.hat <- rep(sigma.hat, times = nrand)
# set outer (nboot) and inner (ndoubleboot)
nboot <- 100
ndoubleboot <- 31
### prepare for boots function that performs a single bootstrap
alpha.star <- matrix(NaN, nboot, length(alpha.hat))
sigma.star <- matrix(NaN, nboot, length(sigma.hat))
nu.star <- matrix(NaN, nboot, length(nu.hat))
se.alpha.star <- alpha.star
se.sigma.star <- sigma.star
se.nu.star <- nu.star
# make boots function
boots <- function(alpha, sigma) {
a.hat <- rep(sigma, times = nrand)
c.star <- rnorm(sum(nrand))
b.star <- a.hat * c.star
eff.star <- c(alpha, b.star)
phi.star <- as.numeric(as.vector(rout2017$obj$origin) +
modmat.tot %*% eff.star)
theta.star <- astertransform(phi.star, rout2017$obj,
to.cond = "conditional", to.mean = "canonical")
y.star <- raster(theta.star, pred, fam, rout2017$obj$root)
y.star <- as.vector(y.star)
rout.star <- reaster(y.star ~ varb + fit : (block), # make sure this matches your model
list(parental=~0 + fit:modmat.siredam2017),
pred, fam, varb, id, root, data = redata2017,
effects = c(alpha, c.star), sigma = sigma)
}
# generate function to compute VaW estimate
VaW<- function (rout2017){
bhat<- rout2017$b
bhat.sire<- bhat[grep("sireID", names(bhat))]
hoom.star <- predict(rout2017$obj,  newcoef = rout2017$alpha)
hoom.star<- matrix(hoom.star, ncol =5)
hoom.star<- hoom.star[ , 5]
# mapping function
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2017$alpha
alpha[12] <- alpha[12] + b # adding fixed effect for fit:block7 (e.g. alpha[12]), make sure this matches your model
hoom.star <- predict(rout2017$obj, newcoef = alpha)
hoom.star<- matrix(hoom.star, ncol = 5)
return(hoom.star[3126, 5]) # return value of 3rd node (seed #) for 3126th indiv (1st indiv in block 7). Change this to whatever your terminal fitness node is (e.g. seed #)
}
fred<- Vectorize(map)
bhat.sire.mu<- fred(bhat.sire)
hoom.star2<- predict(rout2017$obj, newcoef = rout2017$alpha, se.fit=TRUE)
goom.star <- hoom.star2$gradient
moom.star<- goom.star[,5]
moom.star<- matrix(moom.star, ncol=5)
# calcualtion for Va(w)
GC_Va<- 4*moom.star[3126 , 5]^2 * rout2017$nu[1]/map(0) # final calcuation of additive genetic variance for fitness
}
GC_Va.hat <- VaW(rout2017) # generates Va(W) from data
# calculate t for IQR-based confidence interval
t <- (GC_Va.star - GC_Va.hat) / se.GC_Va.star
# set confidence level
conf.level <- 0.95
# generate critical values with t for IQR-based confidence interval
crit <- quantile(t, probs = c((1 - conf.level) / 2, (1 + conf.level) / 2))  # note this uses the t just calculated
# generate IQR and standard deviation measures of scale
foo <- GC_Va.star[1:nboot]    # the outer loop Va's
se.GC_Va.hat <- diff(sort(foo)[c(25,76)])  # middle 50 percent of 100 or so
se.GC_Va.hat_sd <- sd(foo)  # standard deviation calculation of scale
# Conf. Int. for GC_Va with IQR scale metric
GC_Va.hat - rev(crit) * se.GC_Va.hat
# calculate t for standard deviation-based confidence interval
t <- (GC_Va.star - GC_Va.hat) / se.GC_Va.star_sd
# generate critical values with t for standard deviation-based confidence interval
crit <- quantile(t, probs = c((1 - conf.level) / 2, (1 + conf.level) / 2))
# Conf. Int. for GC_Va with standard deviation scale metric
GC_Va.hat - rev(crit) * se.GC_Va.hat_sd
setwd("C:/Users/Mason Kulbaba/Dropbox/Rscripts/chamaecrista-adaptive-capacity/bootstrap/GC/2017")
# load packages
library(aster)
# load raster output
load("rout2017.RData")
# load redata file
load("redata2017.RData")
# load modmat.siredam matrix
load("modmat.siredam2017.RData")
modmat.siredamGC<- as.matrix(modmat.siredam2017)
#set random seed
set.seed(1729)
#########################################################################
### 2. PREPARE FOR BOOTSTRAPPING
#########################################################################
### set up graphical model
pred<- c(0,1,2,3,4) #make sure this matches your model
# designate family for each node in graphical model
fam<- c(1,1,2,2,2) #make sure this matches your model
# generate "hat" estimates from data
alpha.hat <- rout2017$alpha
sigma.hat <- rout2017$sigma
nu.hat <- rout2017$nu
b.hat <- rout2017$b
c.hat <- rout2017$c
sout <- summary(rout2017)
se.alpha.hat <- sout$alpha[ , "Std. Error"]
se.sigma.hat <- sout$sigma[ , "Std. Error"]
se.nu.hat <- sout$nu[ , "Std. Error"]
fixed <- rout2017$fixed
random <- rout2017$random
modmat.tot <- cbind(fixed, Reduce(cbind, random))
nfix <- ncol(fixed)
nrand <- sapply(random, ncol)
a.hat <- rep(sigma.hat, times = nrand)
# set outer (nboot) and inner (ndoubleboot)
nboot <- 100
ndoubleboot <- 31
### prepare for boots function that performs a single bootstrap
alpha.star <- matrix(NaN, nboot, length(alpha.hat))
sigma.star <- matrix(NaN, nboot, length(sigma.hat))
nu.star <- matrix(NaN, nboot, length(nu.hat))
se.alpha.star <- alpha.star
se.sigma.star <- sigma.star
se.nu.star <- nu.star
# make boots function
boots <- function(alpha, sigma) {
a.hat <- rep(sigma, times = nrand)
c.star <- rnorm(sum(nrand))
b.star <- a.hat * c.star
eff.star <- c(alpha, b.star)
phi.star <- as.numeric(as.vector(rout2017$obj$origin) +
modmat.tot %*% eff.star)
theta.star <- astertransform(phi.star, rout2017$obj,
to.cond = "conditional", to.mean = "canonical")
y.star <- raster(theta.star, pred, fam, rout2017$obj$root)
y.star <- as.vector(y.star)
rout.star <- reaster(y.star ~ varb + fit : (block), # make sure this matches your model
list(parental=~0 + fit:modmat.siredam2017),
pred, fam, varb, id, root, data = redata2017,
effects = c(alpha, c.star), sigma = sigma)
}
# generate function to compute VaW estimate
VaW<- function (rout2017){
bhat<- rout2017$b
bhat.sire<- bhat[grep("sireID", names(bhat))]
hoom.star <- predict(rout2017$obj,  newcoef = rout2017$alpha)
hoom.star<- matrix(hoom.star, ncol =5)
hoom.star<- hoom.star[ , 5]
# mapping function
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2017$alpha
alpha[12] <- alpha[12] + b # adding fixed effect for fit:block7 (e.g. alpha[12]), make sure this matches your model
hoom.star <- predict(rout2017$obj, newcoef = alpha)
hoom.star<- matrix(hoom.star, ncol = 5)
return(hoom.star[3126, 5]) # return value of 3rd node (seed #) for 3126th indiv (1st indiv in block 7). Change this to whatever your terminal fitness node is (e.g. seed #)
}
fred<- Vectorize(map)
bhat.sire.mu<- fred(bhat.sire)
hoom.star2<- predict(rout2017$obj, newcoef = rout2017$alpha, se.fit=TRUE)
goom.star <- hoom.star2$gradient
moom.star<- goom.star[,5]
moom.star<- matrix(moom.star, ncol=5)
# calcualtion for Va(w)
GC_Va<- 4*moom.star[3126 , 5]^2 * rout2017$nu[1]/map(0) # final calcuation of additive genetic variance for fitness
}
load("doubleboot_GC2017_run.RData")
# Generate Va(W) from data
GC_Va.hat <- VaW(rout2017) # generates Va(W) from data
# calculate t for IQR-based confidence interval
t <- (GC_Va.star - GC_Va.hat) / se.GC_Va.star
# set confidence level
conf.level <- 0.95
# generate critical values with t for IQR-based confidence interval
crit <- quantile(t, probs = c((1 - conf.level) / 2, (1 + conf.level) / 2))  # note this uses the t just calculated
# generate IQR and standard deviation measures of scale
foo <- GC_Va.star[1:nboot]    # the outer loop Va's
se.GC_Va.hat <- diff(sort(foo)[c(25,76)])  # middle 50 percent of 100 or so
se.GC_Va.hat_sd <- sd(foo)  # standard deviation calculation of scale
# Conf. Int. for GC_Va with IQR scale metric
GC_Va.hat - rev(crit) * se.GC_Va.hat
# calculate t for standard deviation-based confidence interval
t <- (GC_Va.star - GC_Va.hat) / se.GC_Va.star_sd
# generate critical values with t for standard deviation-based confidence interval
crit <- quantile(t, probs = c((1 - conf.level) / 2, (1 + conf.level) / 2))
# Conf. Int. for GC_Va with standard deviation scale metric
GC_Va.hat - rev(crit) * se.GC_Va.hat_sd
table(GC_Va.star)
unique(GC_Va.star)
