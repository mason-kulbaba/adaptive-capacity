p<-p.new
}
return(cbind(p.array,d.array))
}
stack.freqs.plot<-function(p.out,my.title=""){
stacked.freqs<-t(apply(p.out[,c("Ab","AB","ab","aB")],1,cumsum))
plot(stacked.freqs[,"Ab"],ylim=c(0,1),type="l",xlab="Generations",ylab="Frequencies",cex.lab=1.4,cex.axis=1.2,main=my.title,cex.main=1.4)
my.x<-1:n.gens
x.polygon<-c(my.x,rev(my.x))
polygon(x=x.polygon,c(stacked.freqs[,"Ab"],rep(0,n.gens)),col="blue")
polygon(x=x.polygon,c(stacked.freqs[,"AB"],rev(stacked.freqs[,"Ab"])),col="purple")
polygon(x=x.polygon,c(stacked.freqs[,"AB"],rev(stacked.freqs[,"aB"])),col="white")
polygon(x=x.polygon,c(stacked.freqs[,"aB"],rev(stacked.freqs[,"ab"])),col="red")
}
###Neutral Hitchhiking
n.gens<-500
p<-  c(0.001,0.099,0,0.9); names(p)<-c("AB","Ab","aB","ab")
w.add<-c(1,0.95,1,0.95);names(w.add)<-names(p)
w.mat<-outer(w.add,w.add,FUN="+")
layout(t(1:3))
par(mar=c(4,4,3,1))
p.out<-two.loc.sims(p,w.mat,r=0.0005); stack.freqs.plot(p.out,my.title="r=0.0005")
#plot(p.out[,"AB"]+p.out[,"Ab"],type="l",ylim=c(0,1))#lines(p.out[,"AB"]+p.out[,"aB"],col="red")
p.out<-two.loc.sims(p,w.mat,r=0.005); stack.freqs.plot(p.out,my.title="r=0.005")
p.out<-two.loc.sims(p,w.mat,r=0.05);stack.freqs.plot(p.out,my.title="r=0.05")
dev.copy2pdf(file="~/Dropbox/Courses/Popgen_teaching_Notes/figures/selection_recom_interaction/Neutral_Hitchhiking.pdf")
###Deleterious allele Hitchhiking
par(mar=c(4,4.1,3,1))
n.gens<-1000
p<-  c(0.001,0.099,0,0.9); names(p)<-c("AB","Ab","aB","ab")
w.add<-c(0.97,0.93,1,0.95);names(w.add)<-names(p)
w.mat<-outer(w.add,w.add,FUN="+")
layout(t(1:3))
p.out<-two.loc.sims(p,w.mat,r=0.00);stack.freqs.plot(p.out,my.title="r=0.0");
p.out<-two.loc.sims(p,w.mat,r=0.000005);stack.freqs.plot(p.out,my.title="r=0.000005");
p.out<-two.loc.sims(p,w.mat,r=0.0002);stack.freqs.plot(p.out,my.title="r=0.0005");
dev.copy2pdf(file="~/Dropbox/Courses/Popgen_teaching_Notes/figures/Deleterious_Hitchhiking.pdf")
##interference
layout(t(1:2))
n.gens<-1000
p<-  c(0.0,0.01,0.01,0.98); names(p)<-c("AB","Ab","aB","ab")
w.add<-c(1.14,1.08,1.06,1);names(w.add)<-names(p)
w.mat<-outer(w.add,w.add,FUN="+")
p.out<-two.loc.sims(p,w.mat,r=0.00)
stack.freqs.plot(p.out)
p<-  c(0.0,0.01,0.01,0.98); names(p)<-c("AB","Ab","aB","ab")
w.add<-c(1.1,1.06,1.055,1);names(w.add)<-names(p)
w.mat<-outer(w.add,w.add,FUN="+")
p.out<-two.loc.sims(p,w.mat,r=0.001)
stack.freqs.plot(p.out)
dev.copy2pdf(file="~/Dropbox/Courses/Popgen_teaching_Notes/figures/Interference.pdf")
###synergistic alleles & recom
n.gens<-200
layout(t(1:3))
?update.packages
update.packages()
update.packages(ask=FALSE)
install.packages("tidyverse")
?tidyverse
setwd("C:\Users\Mason Kulbaba\Dropbox\Rscripts\chamaecrista-adaptive-capacity\VaW_W_analyses\CS")
#Load reaster
#2015 reaster data
load(file="rout2015.RData")
#2016 reaster data
load(file="rout2016.RData")
#2017 reaster data
load(file="rout2017.RData")
library(aster)
#########################
#Estimate Va(W) for 2015#
#########################
#extract bhat - the estimates of random effects
bhat<- rout2015$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2015$obj, newcoef = rout2015$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[9]= block4),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2015$alpha
alpha[9] <- alpha[9] + b #block 4 effects
hoom <- predict(rout2015$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[1570, 5])# individual in block 4, fourth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
kw_b2015<- bhat.sireGC.mu
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
kw2015den<-density(bhat.sireGC.mu)
kw2015den<- cbind(kw2015den[[1]], kw2015den[[2]])
write.csv(kw2015den, "kw2015den.csv", quote = FALSE, row.names = FALSE)
hoom<- predict(rout2015$obj, newcoef = rout2015$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
KW_Va2015<- 4*moom[1570 ,5]^2 * rout2015$nu[1]/map(0)
KW_Va2015 #3.527548
setwd("C:/Users/Mason Kulbaba/Dropbox/Rscripts/chamaecrista-adaptive-capacity/VaW_W_analyses/KW")
#Load reaster
#2015 reaster data
load(file="rout2015.RData")
#2016 reaster data
load(file="rout2016.RData")
#2017 reaster data
load(file="rout2017.RData")
library(aster)
#########################
#Estimate Va(W) for 2015#
#########################
#extract bhat - the estimates of random effects
bhat<- rout2015$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2015$obj, newcoef = rout2015$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[9]= block4),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2015$alpha
alpha[9] <- alpha[9] + b #block 4 effects
hoom <- predict(rout2015$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[1570, 5])# individual in block 4, fourth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
kw_b2015<- bhat.sireGC.mu
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
kw2015den<-density(bhat.sireGC.mu)
kw2015den<- cbind(kw2015den[[1]], kw2015den[[2]])
write.csv(kw2015den, "kw2015den.csv", quote = FALSE, row.names = FALSE)
hoom<- predict(rout2015$obj, newcoef = rout2015$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
KW_Va2015<- 4*moom[1570 ,5]^2 * rout2015$nu[1]/map(0)
KW_Va2015 #3.527548
#########################
#Estimate Va(W) for 2016#
#########################
#extract bhat - the estimates of random effects
bhat<- rout2016$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2016$obj, newcoef = rout2016$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[10]= block5),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2016$alpha
alpha[10] <- alpha[10] + b #block 5 effects
hoom <- predict(rout2016$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[2251, 5])# individual in block 5, fourth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
kw_b2016<- bhat.sireGC.mu
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
kw2016den<- density(bhat.sireGC.mu)
kw2016den<- cbind(kw2016den[[1]], kw2016den[[2]])
write.csv(kw2016den, "kw2016den.csv", quote = FALSE, row.names = FALSE)
hoom<- predict(rout2016$obj, newcoef = rout2016$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
KW_Va2016<- 4*moom[2251 ,5]^2 * rout2016$nu[1]/map(0)
KW_Va2016 #1.571878
#extract bhat - the estimates of random effects
bhat<- rout2017$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2017$obj, newcoef = rout2017$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[11]= block6),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2017$alpha
alpha[11] <- alpha[11] + b #block 6 effects
hoom <- predict(rout2017$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[2302, 5])# individual in block 6, fourth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
kw_b2017<- bhat.sireGC.mu
kw_bs<- rbind(kw_b2015, kw_b2016, kw_b2017)
write.table(kw_bs, file="KWb_threeyears.csv", sep=",")
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
kw2017den<- density(bhat.sireGC.mu)
kw2017den<- cbind(kw2017den[[1]], kw2017den[[2]])
write.csv(kw2017den, "kw2017den.csv", quote = FALSE, row.names = FALSE)
hoom<- predict(rout2017$obj, newcoef = rout2017$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
KW_Va2017<- 4*moom[2303 ,5]^2 * rout2017$nu[1]/map(0)
KW_Va2017 #1.409605
#################
#Begin with data preparation
#Load 3-year data file for Grey Cloud Dunes
setwd("C:/Users/Mason Kulbaba/Dropbox/Rscripts/chamaecrista-adaptive-capacity/VaW_W_analyses/KW")
kwdat<- read.csv("kwdata.csv")
#divide into year-specific files
kw2015<- subset(kwdat, year==2015)
kw2016<- subset(kwdat, year==2016)
kw2017<- subset(kwdat, year==2017)
#drop unused levels
kw2015<- droplevels(kw2015)
kw2016<- droplevels(kw2016)
kw2017<- droplevels(kw2017)
###################################################################################
# 1. Estimate mean expected fitness in greenhouse genration for 2015 and 2016 year#
###################################################################################
#isolate greenhouse generation from 2016 and 2017 data (only greenhouse cohort in 2015)
kw2016<- subset(kw2016, cohort=="greenhouse")
kw2016<- droplevels(kw2016)
kw2017<- subset(kw2017, cohort=="greenhouse")
kw2017<- droplevels(kw2017)
#make sure maternalID and paternalID is a factor
kw2015$maternalID<- as.factor(kw2015$maternalID)
kw2015$paternalID<- as.factor(kw2015$paternalID)
kw2016$maternalID<- as.factor(kw2016$maternalID)
kw2016$paternalID<- as.factor(kw2016$paternalID)
kw2017$maternalID<- as.factor(kw2017$maternalID)
kw2017$paternalID<- as.factor(kw2017$paternalID)
#set response variables -> these represent variables in graphical model
vars<- c("Germ","flw","total.pods", "total.pods.collected", "totalseeds")
#reshape data so that all response variables are located in a single vector in a new data
#set called "redata"
redata2015 <- reshape(kw2015, varying = list(vars), direction = "long",timevar = "varb", times = as.factor(vars), v.names = "resp")
redata2016 <- reshape(kw2016, varying = list(vars), direction = "long",timevar = "varb", times = as.factor(vars), v.names = "resp")
redata2017 <- reshape(kw2017, varying = list(vars), direction = "long",timevar = "varb", times = as.factor(vars), v.names = "resp")
#Designation of fitness variable for 2015 data
fit <- grepl("totalseeds", as.character(redata2015$varb))
fit<- as.numeric(fit)
redata2015$fit <- fit
#check
with(redata2015, sort(unique(as.character(varb)[fit == 0])))
with(redata2015, sort(unique(as.character(varb)[fit == 1])))
#add a variable "root" to redata files, where value is 1
redata2015<- data.frame(redata2015, root=1)
redata2016<- data.frame(redata2016, root=1)
#make sure block, row, and position are factors
redata2015$block<- as.factor(redata2015$block)
redata2015$row<- as.factor(redata2015$row)
redata2015$position<- as.factor(redata2015$position)
redata2016$block<- as.factor(redata2016$block)
redata2016$row<- as.factor(redata2016$row)
redata2016$position<- as.factor(redata2016$position)
#load aster package
library(aster)
#set graphical mode and dist. for fitness nodes (preds)
pred<- c(0,1,2,3,4)
fam<- c(1,1,2,2,2)
#describe dist. of preds.
sapply(fam.default(), as.character)[fam]
#fixed effect model for 2015
aout2015a<- aster(resp~varb, pred, fam, varb, id, root, data=redata2015)
aout2015<- aster(resp~varb + fit:(block), pred, fam, varb, id, root, data=redata2015)
anova(aout2015a, aout2015)
summary(aout2015, show.graph = T)
#Designate fitness variable for 2016 data
fit <- grepl("totalseeds", as.character(redata2016$varb))
fit<- as.numeric(fit)
redata2016$fit<- fit
#check
with(redata2016, sort(unique(as.character(varb)[fit == 0])))
with(redata2016, sort(unique(as.character(varb)[fit == 1])))
#Fixed-effects aster model for 2016 data
aout2016a<- aster(resp~varb, pred, fam, varb, id, root, data=redata2016)
aout2016<- aster(resp~varb + fit:(block), pred, fam, varb, id, root, data=redata2016)
anova(aout2016a, aout2016)
summary(aout2016, show.graph = T)
#Designation of fitness variable for 2017 data
fit <- grepl("totalseeds", as.character(redata2017$varb))
fit<- as.numeric(fit)
redata2017$fit <- fit
#check
with(redata2017, sort(unique(as.character(varb)[fit == 0])))
with(redata2017, sort(unique(as.character(varb)[fit == 1])))
#add a variable "root" to redata files, where value is 1
redata2017<- data.frame(redata2017, root=1)
#make sure block, row, and position are factors
redata2017$block<- as.factor(redata2017$block)
redata2017$row<- as.factor(redata2017$row)
redata2017$position<- as.factor(redata2017$position)
#check
with(redata2017, sort(unique(as.character(varb)[fit == 0])))
with(redata2017, sort(unique(as.character(varb)[fit == 1])))
#Fixed-effects aster model for 2016 data
aout2017a<- aster(resp~varb, pred, fam, varb, id, root, data=redata2017)
aout2017<- aster(resp~varb + fit:(block), pred, fam, varb, id, root, data=redata2017)
anova(aout2017a, aout2017)
summary(aout2017, show.graph = T)
##############################################################
#Estimate mean fitness for 2015, 2016 (greenhouse cohort), and 2017 (greenhouse cohort) data
#generate MLE of saturated model mean value parameter vector: mu
pout2015<- predict.aster(aout2015, se.fit=TRUE)
pout2016<- predict.aster(aout2016, se.fit=TRUE)
pout2017<- predict.aster(aout2017, se.fit=TRUE)
#make up covariate data for hypothetical
#indivs that meet "typical" criteria:
#Therefore, "make up" covariate data for hypothetical individuals
#that re comparable and obtain mean values for them
##############
#make data.frame of indivudals for each block (1-8)
fred2015 <- data.frame(block=levels(redata2015$block),
Germ=1, flw=1, total.pods=1, total.pods.collected=1, totalseeds=1,root = 1)
fred2017 <- data.frame(block=levels(redata2017$block),
Germ=1, flw=1, total.pods=1, total.pods.collected=1, totalseeds=1,root = 1)
#reshape the "made up data" just as the actual data
renewdata2015 <- reshape(fred2015, varying = list(vars),
direction = "long", timevar = "varb",
times = as.factor(vars), v.names = "resp")
renewdata2017 <- reshape(fred2017, varying = list(vars),
direction = "long", timevar = "varb",
times = as.factor(vars), v.names = "resp")
#make character string from "varb" of renewdata,
#without actual values (e.g., the layers of varb in renewdata)
layer<- gsub("[0-9]", "", as.character(renewdata2015$varb))
layer<- gsub("[0-9]", "", as.character(renewdata2017$varb))
#add layer to renewdata
renewdata2015<- data.frame(renewdata2015, layer= layer)
renewdata2017<- data.frame(renewdata2017, layer= layer)
# add totalseeds in new layer col of renewdata as numeric, called fit
fit<- as.numeric(layer=="totalseeds")
#add fit to renewdata
renewdata2015<- data.frame(renewdata2015, fit = fit)
renewdata2017<- data.frame(renewdata2017, fit = fit)
#Generate fintess estimates and standard errors for each block
nblock<- nrow(fred2015)#2015 and 2017 data has same number of blocks so 2015 file will do for both
nnode<- length(vars)
amat<- array(0, c(nblock, nnode, nblock))
dim(amat)# makes an 8 x 5 x 8 matrix
#only want means for k'th individual that contributes to expected
#fitness, and want to add only totalseeds entries
#makes 8 , 4x8 matrices that
foo<- grepl("totalseeds", vars)
for(k in 1:nblock)
amat[k, foo, k]<- 1
#generate predicted valuses using aout object, with renewdata, and amat format
pout.amat2015<- predict(aout2015, newdata= renewdata2015, varvar= varb,
idvar= id, root = root, se.fit=TRUE, amat = amat)
pout.amat2017<- predict(aout2017, newdata= renewdata2017, varvar= varb,
idvar= id, root = root, se.fit=TRUE, amat = amat)
#combine std.err with estimates, and then round
#to three decimal places
kw2015<- cbind(pout.amat2015$fit, pout.amat2015$se.fit)
kw2017<- cbind(pout.amat2017$fit, pout.amat2017$se.fit)
rownames(kw2015)<- as.character(fred2015$block)
rownames(kw2017)<- as.character(fred2017$block)
colnames(kw2015)<- c("Expected Fitness", "SE")
colnames(kw2017)<- c("Expected Fitness", "SE")
#Calcualtion for 2016 is below and needs to be kept separate, as a different number
#of blocks (for some reason?) is used for "greenhouse" cohhort in this year
#note for some reason "greenhouse" plants only present in blocks 1-7
fred2016 <- data.frame(block=levels(redata2016$block),
Germ=1, flw=1, total.pods=1, total.pods.collected=1, totalseeds=1,root = 1)
renewdata2016 <- reshape(fred2016, varying = list(vars),
direction = "long", timevar = "varb",
times = as.factor(vars), v.names = "resp")
layer<- gsub("[0-9]", "", as.character(renewdata2016$varb))
#add layer
renewdata2016<- data.frame(renewdata2016, layer= layer)
fit<- as.numeric(layer=="totalseeds")
#add fit to renewdata
renewdata2016<- data.frame(renewdata2016, fit = fit)
#Generate fintess estimates and standard errors for each block
nblock<- nrow(fred2016)#all data has same number of blocks so any file will do
nnode<- length(vars)
amat<- array(0, c(nblock, nnode, nblock))
dim(amat)# makes an 7 x 5 x 7 matrix
#only want means for k'th individual that contributes to expected
#fitness, and want to add only totalseeds entries
#makes 8 , 4x8 matrices that
foo<- grepl("totalseeds", vars)
for(k in 1:nblock)
amat[k, foo, k]<- 1
pout.amat2016<- predict(aout2016, newdata= renewdata2016, varvar= varb,
idvar= id, root = root, se.fit=TRUE, amat = amat)
kw2016<- cbind(pout.amat2016$fit, pout.amat2016$se.fit)
rownames(kw2016)<- as.character(fred2016$block)
colnames(kw2016)<- c("Expected Fitness", "SE")
round(kw2016, 3)
#####################################################################
#The median expected fitness for each year is used to represent     #
#the site-specific fitness. The block effects representing these    #
# fitness values will be used to calcualte and convert  Va(W)       #
#estimates from the canonical to man-value parameter scale          #
#####################################################################
round(kw2015, 3) # median: block 4 - 3.02 (1.227)
round(kw2016, 3) # median: block 5 - 1.884 (0.565)
round(kw2017, 3) # median: block 6 - 1.081 (0.176)
kwdat<- read.csv("kwdata.csv")
#subset only greenhouse cohort form all three years of data
gh<- subset(gcdat, cohort=="greenhouse")
gh<- droplevels(gh)
#make sure block, row, and position are factors
gh$block<- as.factor(gh$block)
gh$row<- as.factor(gh$row)
gh$position<- as.factor(gh$position)
gh$year<- as.factor(gh$year)
gh$maternalID<- as.factor(gh$maternalID)
gh$paternalID<- as.factor(gh$paternalID)
#set response variables -> these represent variables in graphical model
vars<- c("Germ","flw","total.pods", "total.pods.collected", "totalseeds")
#reshape data so that all response variables are located in a single vector in a new data
#set called "redata"
redata <- reshape(gh, varying = list(vars), direction = "long",timevar = "varb", times = as.factor(vars), v.names = "resp")
#Designation of fitness variable: totalseeds
fit <- grepl("totalseeds", as.character(redata$varb))
fit<- as.numeric(fit)
redata$fit <- fit
#check
with(redata, sort(unique(as.character(varb)[fit == 0])))
with(redata, sort(unique(as.character(varb)[fit == 1])))
#add a variable "root" to redata files, where value is 1
redata<- data.frame(redata, root=1)
####combine maternal and paternal into a single parental effect to be estimated
modmat.sire <- model.matrix(~ 0 + fit:paternalID, redata)
modmat.dam <- model.matrix(~ 0 + fit:maternalID, redata)
modmat.siredam <- cbind(modmat.sire,modmat.dam)
#G x Time reaster analysis
routGxTime.a<- reaster(resp~varb,list(parental=~0 + fit:modmat.siredam),
+pred, fam, varb, id, root, data=redata)
kwdat<- read.csv("kwdata.csv")
#subset only greenhouse cohort form all three years of data
gh<- subset(kwdat, cohort=="greenhouse")
gh<- droplevels(gh)
#make sure block, row, and position are factors
gh$block<- as.factor(gh$block)
gh$row<- as.factor(gh$row)
gh$position<- as.factor(gh$position)
gh$year<- as.factor(gh$year)
gh$maternalID<- as.factor(gh$maternalID)
gh$paternalID<- as.factor(gh$paternalID)
#set response variables -> these represent variables in graphical model
vars<- c("Germ","flw","total.pods", "total.pods.collected", "totalseeds")
#reshape data so that all response variables are located in a single vector in a new data
#set called "redata"
redata <- reshape(gh, varying = list(vars), direction = "long",timevar = "varb", times = as.factor(vars), v.names = "resp")
#Designation of fitness variable: totalseeds
fit <- grepl("totalseeds", as.character(redata$varb))
fit<- as.numeric(fit)
redata$fit <- fit
#check
with(redata, sort(unique(as.character(varb)[fit == 0])))
with(redata, sort(unique(as.character(varb)[fit == 1])))
#add a variable "root" to redata files, where value is 1
redata<- data.frame(redata, root=1)
####combine maternal and paternal into a single parental effect to be estimated
modmat.sire <- model.matrix(~ 0 + fit:paternalID, redata)
modmat.dam <- model.matrix(~ 0 + fit:maternalID, redata)
modmat.siredam <- cbind(modmat.sire,modmat.dam)
#G x Time reaster analysis
routGxTime.a<- reaster(resp~varb,list(parental=~0 + fit:modmat.siredam),
+pred, fam, varb, id, root, data=redata)
