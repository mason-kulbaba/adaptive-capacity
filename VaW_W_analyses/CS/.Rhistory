modmat.siredam2015 <- cbind(modmat.sire2015,modmat.dam2015)
modmat.sire2016 <- model.matrix(~ 0 + fit:paternalID, redata2016)
modmat.dam2016 <- model.matrix(~ 0 + fit:maternalID, redata2016)
modmat.siredam2016 <- cbind(modmat.sire2016,modmat.dam2016)
modmat.sire2017 <- model.matrix(~ 0 + fit:paternalID, redata2017)
modmat.dam2017 <- model.matrix(~ 0 + fit:maternalID, redata2017)
modmat.siredam2017 <- cbind(modmat.sire2017,modmat.dam2017)
#save(redata2015, file="redata2015.RData")
#save(redata2016, file="redata2016.RData")
#save(redata2017, file="redata2017.RData")
#save(modmat.siredam2015, file="modmat.siredam2015.RData")
#save(modmat.siredam2016, file="modmat.siredam2016.RData")
#save(modmat.siredam2017, file="modmat.siredam2017.RData")
#Reaster analyses
#NOTE: we will use the same graphical model and statistical distributions that we used
#      in the fixed-effects aster models to estiamte mean expected fitness
rout2015b<- reaster(resp~varb +fit:(block),list(parental=~0 + modmat.siredam2015),
+pred, fam, varb, id, root, data=redata2015)
summary(rout2015b)
save(rout2015b, file="rout2015b.RData")
rout2016b<- reaster(resp~varb +fit:(block),list(parental=~0 + modmat.siredam2016),
+pred, fam, varb, id, root, data=redata2016)
summary(rout2016b)
save(rout2016b, file="rout2016b.RData")
rout2017b<- reaster(resp~varb +fit:(block),list(parental=~0 + modmat.siredam2017),
+pred, fam, varb, id, root, data=redata2017)
summary(rout2017b)
save(rout2017b, file="rout2017b.RData")
year data file for CERA
setwd("C:/Users/Mason Kulbaba/Dropbox/git/adaptive-capacity/VaW_W_analyses/CS")
csdat<- read.csv("csdata.csv")
#divide into year-specific files
cs2015<- subset(csdat, year==2015)
cs2016<- subset(csdat, year==2016)
cs2017<- subset(csdat, year==2017)
#drop unused levels
cs2015<- droplevels(cs2015)
cs2016<- droplevels(cs2016)
cs2017<- droplevels(cs2017)
###################################################################################
# 1. Estimate mean expected fitness in greenhouse genration for 2015 and 2016 year#
###################################################################################
#isolate greenhouse generation from 2016 and 2017 data (only greenhouse cohort in 2015)
cs2016<- subset(cs2016, cohort=="greenhouse")
cs2016<- droplevels(cs2016)
cs2017<- subset(cs2017, cohort=="greenhouse")
cs2017<- droplevels(cs2017)
#make sure maternalID and paternalID is a factor
cs2015$maternalID<- as.factor(cs2015$maternalID)
cs2015$paternalID<- as.factor(cs2015$paternalID)
cs2016$maternalID<- as.factor(cs2016$maternalID)
cs2016$paternalID<- as.factor(cs2016$paternalID)
cs2017$maternalID<- as.factor(cs2017$maternalID)
cs2017$paternalID<- as.factor(cs2017$paternalID)
#set response variables -> these represent variables in graphical model
vars<- c("Germ","flw","total.pods", "total.pods.collected", "totalseeds")
#reshape data so that all response variables are located in a single vector in a new data
#set called "redata"
redata2015 <- reshape(cs2015, varying = list(vars), direction = "long",timevar = "varb", times = as.factor(vars), v.names = "resp")
redata2016 <- reshape(cs2016, varying = list(vars), direction = "long",timevar = "varb", times = as.factor(vars), v.names = "resp")
redata2017 <- reshape(cs2017, varying = list(vars), direction = "long",timevar = "varb", times = as.factor(vars), v.names = "resp")
#Designation of fitness variable for 2015 data
fit <- grepl("totalseeds", as.character(redata2015$varb))
fit<- as.numeric(fit)
redata2015$fit <- fit
#check
with(redata2015, sort(unique(as.character(varb)[fit == 0])))
with(redata2015, sort(unique(as.character(varb)[fit == 1])))
#add a variable "root" to redata files, where value is 1
redata2015<- data.frame(redata2015, root=1)
redata2016<- data.frame(redata2016, root=1)
#make sure block, row, and position are factors
redata2015$block<- as.factor(redata2015$block)
redata2015$row<- as.factor(redata2015$row)
redata2015$position<- as.factor(redata2015$position)
redata2016$block<- as.factor(redata2016$block)
redata2016$row<- as.factor(redata2016$row)
redata2016$position<- as.factor(redata2016$position)
#load aster package
library(aster)
#set graphical mode and dist. for fitness nodes (preds)
pred<- c(0,1,2,3,4)
fam<- c(1,1,2,2,2)
#describe dist. of preds.
sapply(fam.default(), as.character)[fam]
#fixed effect model for 2015
aout2015a<- aster(resp~varb, pred, fam, varb, id, root, data=redata2015)
aout2015<- aster(resp~varb + fit:(block), pred, fam, varb, id, root, data=redata2015)
anova(aout2015a, aout2015)
summary(aout2015, show.graph = T)
#Designate fitness variable for 2016 data
fit <- grepl("totalseeds", as.character(redata2016$varb))
fit<- as.numeric(fit)
redata2016$fit<- fit
#check
with(redata2016, sort(unique(as.character(varb)[fit == 0])))
with(redata2016, sort(unique(as.character(varb)[fit == 1])))
#Fixed-effects aster model for 2016 data
aout2016a<- aster(resp~varb, pred, fam, varb, id, root, data=redata2016)
aout2016<- aster(resp~varb + fit:(block), pred, fam, varb, id, root, data=redata2016)
anova(aout2016a, aout2016)
summary(aout2016, show.graph = T)
#Designation of fitness variable for 2017 data
fit <- grepl("totalseeds", as.character(redata2017$varb))
fit<- as.numeric(fit)
redata2017$fit <- fit
#check
with(redata2017, sort(unique(as.character(varb)[fit == 0])))
with(redata2017, sort(unique(as.character(varb)[fit == 1])))
#add a variable "root" to redata files, where value is 1
redata2017<- data.frame(redata2017, root=1)
#make sure block, row, and position are factors
redata2017$block<- as.factor(redata2017$block)
redata2017$row<- as.factor(redata2017$row)
redata2017$position<- as.factor(redata2017$position)
#check
with(redata2017, sort(unique(as.character(varb)[fit == 0])))
with(redata2017, sort(unique(as.character(varb)[fit == 1])))
#Fixed-effects aster model for 2016 data
aout2017a<- aster(resp~varb, pred, fam, varb, id, root, data=redata2017)
aout2017<- aster(resp~varb + fit:(block), pred, fam, varb, id, root, data=redata2017)
anova(aout2017a, aout2017)
summary(aout2017, show.graph = T)
##############################################################
#Estimate mean fitness for 2015, 2016 (greenhouse cohort), and 2017 (greenhouse cohort) data
#generate MLE of saturated model mean value parameter vector: mu
pout2015<- predict.aster(aout2015, se.fit=TRUE)
pout2016<- predict.aster(aout2016, se.fit=TRUE)
pout2017<- predict.aster(aout2017, se.fit=TRUE)
#make up covariate data for hypothetical
#indivs that meet "typical" criteria:
#Therefore, "make up" covariate data for hypothetical individuals
#that re comparable and obtain mean values for them
##############
#make data.frame of indivudals for each block (1-8)
fred2015 <- data.frame(block=levels(redata2015$block),
Germ=1, flw=1, total.pods=1, total.pods.collected=1, totalseeds=1,root = 1)
fred2016 <- data.frame(block=levels(redata2016$block),
Germ=1, flw=1, total.pods=1, total.pods.collected=1, totalseeds=1,root = 1)
fred2017 <- data.frame(block=levels(redata2017$block),
Germ=1, flw=1, total.pods=1, total.pods.collected=1, totalseeds=1,root = 1)
#reshape the "made up data" just as the actual data
renewdata2015 <- reshape(fred2015, varying = list(vars),
direction = "long", timevar = "varb",
times = as.factor(vars), v.names = "resp")
renewdata2016 <- reshape(fred2016, varying = list(vars),
direction = "long", timevar = "varb",
times = as.factor(vars), v.names = "resp")
renewdata2017 <- reshape(fred2017, varying = list(vars),
direction = "long", timevar = "varb",
times = as.factor(vars), v.names = "resp")
#make character string from "varb" of renewdata,
#without actual values (e.g., the layers of varb in renewdata)
layer<- gsub("[0-9]", "", as.character(renewdata2015$varb))
layer<- gsub("[0-9]", "", as.character(renewdata2016$varb))
layer<- gsub("[0-9]", "", as.character(renewdata2017$varb))
#add layer to renewdata
renewdata2015<- data.frame(renewdata2015, layer= layer)
renewdata2016<- data.frame(renewdata2016, layer= layer)
renewdata2017<- data.frame(renewdata2017, layer= layer)
# add totalseeds in new layer col of renewdata as numeric, called fit
fit<- as.numeric(layer=="totalseeds")
#add fit to renewdata
renewdata2015<- data.frame(renewdata2015, fit = fit)
renewdata2016<- data.frame(renewdata2016, fit = fit)
renewdata2017<- data.frame(renewdata2017, fit = fit)
#Generate fintess estimates and standard errors for each block
nblock<- nrow(fred2015)#all years have same number of blocks so 2015 file will do for both
nnode<- length(vars)
amat<- array(0, c(nblock, nnode, nblock))
dim(amat)# makes an 4 x 5 x 4 matrix
#only want means for k'th individual that contributes to expected
#fitness, and want to add only totalseeds entries
#makes 8 , 4x8 matrices that
foo<- grepl("totalseeds", vars)
for(k in 1:nblock)
amat[k, foo, k]<- 1
#generate predicted valuses using aout object, with renewdata, and amat format
pout.amat2015<- predict(aout2015, newdata= renewdata2015, varvar= varb,
idvar= id, root = root, se.fit=TRUE, amat = amat)
pout.amat2016<- predict(aout2016, newdata= renewdata2016, varvar= varb,
idvar= id, root = root, se.fit=TRUE, amat = amat)
pout.amat2017<- predict(aout2017, newdata= renewdata2017, varvar= varb,
idvar= id, root = root, se.fit=TRUE, amat = amat)
#combine std.err with estimates, and then round
#to three decimal places
cs2015<- cbind(pout.amat2015$fit, pout.amat2015$se.fit)
cs2016<- cbind(pout.amat2016$fit, pout.amat2016$se.fit)
cs2017<- cbind(pout.amat2017$fit, pout.amat2017$se.fit)
rownames(cs2015)<- as.character(fred2015$block)
rownames(cs2016)<- as.character(fred2016$block)
rownames(cs2017)<- as.character(fred2017$block)
colnames(cs2015)<- c("Expected Fitness", "SE")
colnames(cs2016)<- c("Expected Fitness", "SE")
colnames(cs2017)<- c("Expected Fitness", "SE")
#####################################################################
#The median expected fitness for each year is used to represent     #
#the site-specific fitness. The block effects representing these    #
# fitness values will be used to calcualte and convert  Va(W)       #
#estimates from the canonical to man-value parameter scale          #
#####################################################################
round(cs2015, 3) # median: block 1 - 1.795 (0.243)
round(cs2016, 3) # median: block 2 - 0.725 (0.112)
round(cs2017, 3) # median: block 3 - 1.243 (0.253)
#############################################################################
# 2. Reaster analyses for 2015, 2016, and 2017 greenhouse cohort. For clarity, the
#    actual calculation of Va(W) will be performed in a different script (Vaw_Calculation.R).
####combine maternal and paternal into a single parental effect to be estimated
modmat.sire2015 <- model.matrix(~ 0 + fit:paternalID, redata2015)
modmat.dam2015 <- model.matrix(~ 0 + fit:maternalID, redata2015)
modmat.siredam2015 <- cbind(modmat.sire2015,modmat.dam2015)
modmat.sire2016 <- model.matrix(~ 0 + fit:paternalID, redata2016)
modmat.dam2016 <- model.matrix(~ 0 + fit:maternalID, redata2016)
modmat.siredam2016 <- cbind(modmat.sire2016,modmat.dam2016)
modmat.sire2017 <- model.matrix(~ 0 + fit:paternalID, redata2017)
modmat.dam2017 <- model.matrix(~ 0 + fit:maternalID, redata2017)
modmat.siredam2017 <- cbind(modmat.sire2017,modmat.dam2017)
#save(redata2015, file="redata2015.RData")
#save(redata2016, file="redata2016.RData")
#save(redata2017, file="redata2017.RData")
#save(modmat.siredam2015, file="modmat.siredam2015.RData")
#save(modmat.siredam2016, file="modmat.siredam2016.RData")
#save(modmat.siredam2017, file="modmat.siredam2017.RData")
#Reaster analyses
#NOTE: we will use the same graphical model and statistical distributions that we used
#      in the fixed-effects aster models to estiamte mean expected fitness
rout2015b<- reaster(resp~varb +fit:(block),list(parental=~0 + modmat.siredam2015),
+pred, fam, varb, id, root, data=redata2015)
summary(rout2015b)
save(rout2015b, file="rout2015b.RData")
rout2016b<- reaster(resp~varb +fit:(block),list(parental=~0 + modmat.siredam2016),
+pred, fam, varb, id, root, data=redata2016)
summary(rout2016b)
save(rout2016b, file="rout2016b.RData")
rout2017b<- reaster(resp~varb +fit:(block),list(parental=~0 + modmat.siredam2017),
+pred, fam, varb, id, root, data=redata2017)
summary(rout2017b)
save(rout2017b, file="rout2017b.RData")
from the three reaster output files generated in: KW_W_reaster_analyses.R
setwd("C:/Users/Mason Kulbaba/Dropbox/git/adaptive-capacity/VaW_W_analyses/KW")
#Load reaster
#2015 reaster data
load(file="rout2015b.RData")
#2016 reaster data
load(file="rout2016b.RData")
#2017 reaster data
load(file="rout2017b.RData")
library(aster)
#########################
#Estimate Va(W) for 2015#
#########################
#extract bhat - the estimates of random effects
bhat<- rout2015b$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2015b$obj, newcoef = rout2015b$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[9]= block4),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2015b$alpha
alpha[9] <- alpha[9] + b #block 4 effects
hoom <- predict(rout2015b$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[1570, 5])# individual in block 4, fourth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
kw_b2015<- bhat.sireGC.mu
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
kw2015den<-density(bhat.sireGC.mu)
kw2015den<- cbind(kw2015den[[1]], kw2015den[[2]])
write.csv(kw2015den, "kw2015den.csv", quote = FALSE, row.names = FALSE)
hoom<- predict(rout2015b$obj, newcoef = rout2015b$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
KW_Va2015<- 4*moom[1570 ,5]^2 * rout2015b$nu[1]/map(0)
KW_Va2015
#extract bhat - the estimates of random effects
bhat<- rout2016b$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2016b$obj, newcoef = rout2016b$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[10]= block5),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2016b$alpha
alpha[10] <- alpha[10] + b #block 5 effects
hoom <- predict(rout2016b$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[2251, 5])# individual in block 5, fourth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
kw_b2016<- bhat.sireGC.mu
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
kw2016den<- density(bhat.sireGC.mu)
kw2016den<- cbind(kw2016den[[1]], kw2016den[[2]])
write.csv(kw2016den, "kw2016den.csv", quote = FALSE, row.names = FALSE)
hoom<- predict(rout2016b$obj, newcoef = rout2016b$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
KW_Va2016<- 4*moom[2251 ,5]^2 * rout2016b$nu[1]/map(0)
KW_Va2016 #1.571878
#recall
################
#extract bhat - the estimates of random effects
bhat<- rout2017b$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2017b$obj, newcoef = rout2017b$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[11]= block6),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2017b$alpha
alpha[11] <- alpha[11] + b #block 6 effects
hoom <- predict(rout2017b$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[2302, 5])# individual in block 6, fourth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
kw_b2017<- bhat.sireGC.mu
kw_bs<- rbind(kw_b2015, kw_b2016, kw_b2017)
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
kw2017den<- density(bhat.sireGC.mu)
kw2017den<- cbind(kw2017den[[1]], kw2017den[[2]])
hoom<- predict(rout2017b$obj, newcoef = rout2017b$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
KW_Va2017<- 4*moom[2303 ,5]^2 * rout2017b$nu[1]/map(0)
KW_Va2017 #1.409605
aster output files generated in: CS_W_reaster_analyses.R
setwd("C:/Users/Mason Kulbaba/Dropbox/git/adaptive-capacity/VaW_W_analyses/CS")
#Load reaster
#2015 reaster data
load(file="rout2015b.RData")
#2016 reaster data
load(file="rout2016b.RData")
#2017 reaster data
load(file="rout2017b.RData")
library(aster)
#########################
#Estimate Va(W) for 2015#
#########################
#extract bhat - the estimates of random effects
bhat<- rout2015b$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2015b$obj, newcoef = rout2015b$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[6]= block1),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2015b$alpha
alpha[6] <- alpha[6] + b #block 1 effects
hoom <- predict(rout2015b$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[1, 5])# individual in block 1, fifth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
cs_b2015<- bhat.sireGC.mu
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
cs2015den<-density(bhat.sireGC.mu)
cs2015den<- cbind(cs2015den[[1]], cs2015den[[2]])
write.csv(cs2015den, "cs2015den.csv", quote = FALSE, row.names = FALSE)
hoom<- predict(rout2015b$obj, newcoef = rout2015b$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
CS_Va2015<- 4*moom[1 ,5]^2 * rout2015b$nu[1]/map(0)
CS_Va2015 #3.204069
#extract bhat - the estimates of random effects
bhat<- rout2016b$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2016b$obj, newcoef = rout2016b$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[7]= block2),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2016b$alpha
alpha[7] <- alpha[7] + b #block 2 effects
hoom <- predict(rout2016b$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[251, 5])# individual in block 2, fifth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
cs_b2016<- bhat.sireGC.mu
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
cs2016den<- density(bhat.sireGC.mu)
cs2016den<- cbind(cs2016den[[1]], cs2016den[[2]])
hoom<- predict(rout2016b$obj, newcoef = rout2016b$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
CS_Va2016<- 4*moom[251 ,5]^2 * rout2016b$nu[1]/map(0)
CS_Va2016 #0.8562831
#extract bhat - the estimates of random effects
bhat<- rout2017b$b
#extract the sire effects
bhat.sire<- bhat[grep("paternalID", names(bhat))]
#stem plot of bhat estimates
stem(bhat.sire)#the canonical estimates "look" somewhat normal...as they should
hoom <- predict(rout2017b$obj, newcoef = rout2017b$alpha)
hoom<- matrix(hoom, ncol =5)
hoom<- hoom[ , 5]
#add a component of b_hat that we want to map to the mean value
#parameter scale (from canoonical scale) to fit:block1 fixed effect (alpha[8]= block3),
#predict, and take value of fourth node for first indiv.
map <- function(b) {
stopifnot(length(b) == 1)
stopifnot(is.finite(b))
alpha <- rout2017b$alpha
alpha[8] <- alpha[8] + b #block 3 effects
hoom <- predict(rout2017b$obj, newcoef = alpha)
hoom <- matrix(hoom, ncol = 5)
return(hoom[971, 5])# individual in block 3, fifth node
}
#vectorize mapping function
fred<- Vectorize(map)
#plot the curve
curve(fred, from = -1 / 2, to = 1/2, xlab="b", ylab=expression(mu(b)))
#use the mapping function "fred" to convert the sire effects from the
#canonical to mean-value parameter scale
bhat.sireGC.mu<- fred(bhat.sire)
cs_b2017<- bhat.sireGC.mu
cs_bs<- rbind(cs_b2015, cs_b2016, cs_b2017)
write.table(cs_bs, file="CSb_threeyears.csv", sep=",")
stem(bhat.sireGC.mu)#no longer normal as expected
#generate probability density distribution
cs2017den<- density(bhat.sireGC.mu)
cs2017den<- cbind(cs2017den[[1]], cs2017den[[2]])
hoom<- predict(rout2017b$obj, newcoef = rout2017b$alpha, se.fit=TRUE)
goom <- hoom$gradient
moom<- goom[,5]
moom<- matrix(moom, ncol=5)
#this is additive genetic variation for fitness!
CS_Va2017<- 4*moom[971 ,5]^2 * rout2017b$nu[1]/map(0)
CS_Va2017 #1.572956
